{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pfA1XNq2RnI"
   },
   "source": [
    "# 3D Data Processing\n",
    "\n",
    "---\n",
    "A.A. 2024 - Wanmeng Li, Daniel Fusaro\n",
    "---\n",
    "\n",
    "\n",
    "## Lab - PointNet: Point Cloud 3D Descriptors\n",
    "\n",
    "original paper -\n",
    "[PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://web.stanford.edu/~rqi/pointnet/)\n",
    "\n",
    "dataset link: https://drive.google.com/drive/folders/1IweJGcOeOZN3wY79i2jFt3JE1bd7G51Z?usp=share_link\n",
    "\n",
    "SHOT descriptions: [lecture](https://stem.elearning.unipd.it/pluginfile.php/517107/mod_resource/content/25/Slide_3DP_13_3D%20Local%20Descriptors.pdf)\n",
    "\n",
    "To add a link to the dataset in your Google Drive main folder, you need to:\n",
    "\n",
    " - Click on the link\n",
    " - Right click on \"dataset\"\n",
    " - Click Add shortcut to Drive\n",
    "\n",
    "When you will mount your drive folder in Colab you will find this folder without the need of re-uploading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hc7eaUqkcmAz",
    "outputId": "c6a0c7e3-fcc9-47c2-e2fc-bf995178185c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# pyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# a nice training progress bar\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSyKEXWMmI2Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "running_on_colab = True\n",
    "\n",
    "if running_on_colab:\n",
    "    # useful for visualization\n",
    "    ## note: it's not necessary to restart the notebook environment after installation\n",
    "    !pip install open3d\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "# visualization\n",
    "import open3d as o3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuR9palyGqil"
   },
   "source": [
    "# Connect and mount your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjgl1d34-CWw",
    "outputId": "f33e339e-47a3-4726-b4ec-84c2c1042265"
   },
   "outputs": [],
   "source": [
    "if running_on_colab:\n",
    "    from google.colab import drive\n",
    "    drive_path = '/content/drive'\n",
    "    drive.mount(drive_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK1CJSoJGvi7"
   },
   "source": [
    "# General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LWQSdhp3CiT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if running_on_colab:\n",
    "    dataset_path_train = os.path.join(drive_path, \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"train\")\n",
    "    dataset_path_valid = os.path.join(drive_path, \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"valid\")\n",
    "    dataset_path_test = os.path.join(drive_path,  \"MyDrive\", \"3D_dp_dataset\", \"3dshapes\", \"test\")\n",
    "else:\n",
    "    dataset_path_train = os.path.join(\"datasets\", \"train\")\n",
    "    dataset_path_valid = os.path.join(\"datasets\", \"valid\")\n",
    "    dataset_path_test = os.path.join(\"datasets\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWcO-JoNzH17",
    "tags": []
   },
   "source": [
    "# Visualization Example\n",
    "In order to visualize colored point clouds we make use of the Python package *Open3D*.\n",
    "\n",
    "Unfortunately, the original doesn't run on Colab.\n",
    "So, we replace the drawing function with a custom one (*draw_geometries*) that allows for rendering here on Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ceZKVwpfdG0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if running_on_colab:\n",
    "    def draw_geometries(geometries):\n",
    "        graph_objects = []\n",
    "\n",
    "        for geometry in geometries:\n",
    "            geometry_type = geometry.get_geometry_type()\n",
    "\n",
    "            if geometry_type == o3d.geometry.Geometry.Type.PointCloud:\n",
    "                points = np.asarray(geometry.points)\n",
    "                colors = None\n",
    "                if geometry.has_colors():\n",
    "                    colors = np.asarray(geometry.colors)\n",
    "                elif geometry.has_normals():\n",
    "                    colors = (0.5, 0.5, 0.5) + np.asarray(geometry.normals) * 0.5\n",
    "                else:\n",
    "                    geometry.paint_uniform_color((1.0, 0.0, 0.0))\n",
    "                    colors = np.asarray(geometry.colors)\n",
    "\n",
    "                scatter_3d = go.Scatter3d(x=points[:,0], y=points[:,1], z=points[:,2], mode='markers', marker=dict(size=1, color=colors))\n",
    "                graph_objects.append(scatter_3d)\n",
    "\n",
    "            if geometry_type == o3d.geometry.Geometry.Type.TriangleMesh:\n",
    "                triangles = np.asarray(geometry.triangles)\n",
    "                vertices = np.asarray(geometry.vertices)\n",
    "                colors = None\n",
    "                if geometry.has_triangle_normals():\n",
    "                    colors = (0.5, 0.5, 0.5) + np.asarray(geometry.triangle_normals) * 0.5\n",
    "                    colors = tuple(map(tuple, colors))\n",
    "                else:\n",
    "                    colors = (1.0, 0.0, 0.0)\n",
    "\n",
    "                mesh_3d = go.Mesh3d(x=vertices[:,0], y=vertices[:,1], z=vertices[:,2], i=triangles[:,0], j=triangles[:,1], k=triangles[:,2], facecolor=colors, opacity=0.50)\n",
    "                graph_objects.append(mesh_3d)\n",
    "\n",
    "        fig = go.Figure(\n",
    "            data=graph_objects,\n",
    "            layout=dict(\n",
    "                scene=dict(\n",
    "                    xaxis=dict(visible=False),\n",
    "                    yaxis=dict(visible=False),\n",
    "                    zaxis=dict(visible=False),\n",
    "                    aspectmode='data'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywtBnEqw10u3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "anchor_color   = [0, 0, 1.0] # blue\n",
    "positive_color = [0, 1.0, 0] # green\n",
    "negative_color = [1.0, 0, 0] # red\n",
    "p_colors = [anchor_color, positive_color, negative_color]\n",
    "\n",
    "def visualize( pointcloud:np.array =None,\n",
    "               anchor    :np.array =None,\n",
    "               positive  :np.array =None,\n",
    "               negative  :np.array =None,\n",
    "               radius    :np.array =None,\n",
    "               rot_mat   :np.array =None):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "      pointcloud : numpy array of 3D points\n",
    "      anchor     : anchor point\n",
    "      positive   : \n",
    "      negative   : \n",
    "    \"\"\"\n",
    "    geoms = []\n",
    "    if pointcloud is not None:\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(pointcloud)\n",
    "        pcd.paint_uniform_color([0.6, 0.6, 0.6])\n",
    "        if rot_mat is not None:\n",
    "            pcd.rotate(rot_mat, center=(0, 0, 0))\n",
    "        geoms.append(pcd)\n",
    "    for point, color in zip([anchor, positive, negative], p_colors):\n",
    "        if point is not None:\n",
    "            assert radius is not None\n",
    "            sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius, resolution=20)\n",
    "            sphere.translate(point)\n",
    "            sphere.paint_uniform_color(color)\n",
    "            geoms.append(sphere)\n",
    "    # visualize the colored point cloud\n",
    "    if running_on_colab:\n",
    "        draw_geometries(geoms)\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries(geoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLp113kezNBG",
    "tags": []
   },
   "source": [
    "# PointCloud Dataset\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
    "\n",
    "* `__init__` to initialize your dataset. For example, if your dataset fits in memory, you can load the entire dataset in a list, or you can just store the list of dataset files.\n",
    "* `__len__` so that len(dataset) returns the size of the dataset.\n",
    "* `__getitem__` to support indexing such that `dataset[i]` can be used to get  the i-th sample\n",
    "\n",
    "Therefore, the structure of the class is:\n",
    "\n",
    "```\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, init_parameters):\n",
    "        self.param1 = param1\n",
    "        [...]\n",
    "\n",
    "    def __len__(self):\n",
    "        [...]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        [...]\n",
    "\n",
    "        return sample[idx]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2NuVvQCweUS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, \n",
    "                dataset_path: str,\n",
    "                samples_per_epoch: int,\n",
    "                points_to_sample:int = 200000,\n",
    "                radius:float =0.02,\n",
    "                min_dist=1.5e-2,\n",
    "                N = 750,\n",
    "                noise_mean=0,\n",
    "                noise_variance = 6e-5,\n",
    "                is_test_set=False):\n",
    "        \"\"\"\n",
    "          INPUT\n",
    "              dataset_path: path to the dataset folder\n",
    "              transform   : transform function to apply to point cloud\n",
    "        \"\"\"\n",
    "        \n",
    "        self.radius = radius\n",
    "        self.min_dist = min_dist\n",
    "        self.N = N\n",
    "        self.samples_per_epoch = samples_per_epoch\n",
    "        self.points_to_sample = points_to_sample\n",
    "        self.noise_mean = noise_mean\n",
    "        self.noise_variance = noise_variance\n",
    "        self.is_test_set = is_test_set\n",
    "        \n",
    "        # _n means noised version\n",
    "        self.mesh = []\n",
    "        self.pcds, self.pcds_n = [], []\n",
    "        self.KDtrees, self.KDtrees_n = [], []\n",
    "\n",
    "        ## if it's the test set, pre-define a random rotation matrix\n",
    "        if self.is_test_set:\n",
    "            self.common_rot_mat = self.get_xyz_random_rotation()\n",
    "        \n",
    "        for file in glob.glob(dataset_path + \"/*.ply\"):\n",
    "            print(\"parsing file\", file)\n",
    "            mesh = o3d.io.read_triangle_mesh(file)\n",
    "            pcd = mesh.sample_points_uniformly(self.points_to_sample)\n",
    "            if self.is_test_set:\n",
    "                pcd.rotate(self.common_rot_mat.as_matrix(), center=(0, 0, 0))\n",
    "            pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "            \n",
    "            pcd_n = self.apply_noise(mesh.sample_points_uniformly(self.points_to_sample), self.noise_mean, self.noise_variance)\n",
    "            if self.is_test_set:\n",
    "                pcd_n.rotate(self.common_rot_mat.as_matrix(), center=(0, 0, 0))\n",
    "            pcd_n_tree = o3d.geometry.KDTreeFlann(pcd_n)\n",
    "            \n",
    "            self.mesh.append(mesh)\n",
    "            \n",
    "            self.pcds.append(np.asarray(pcd.points))\n",
    "            self.pcds_n.append(np.asarray(pcd_n.points))\n",
    "            \n",
    "            self.KDtrees.append(pcd_tree)\n",
    "            self.KDtrees_n.append(pcd_n_tree)\n",
    "    \n",
    "    # function to apply noise\n",
    "    def apply_noise(self, pcd, mu, sigma):\n",
    "        noisy_pcd = copy.deepcopy(pcd)\n",
    "        points = np.asarray(noisy_pcd.points)\n",
    "        points += np.random.normal(mu, sigma, size=points.shape)\n",
    "        noisy_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        return noisy_pcd\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples_per_epoch\n",
    "    \n",
    "    def get_xyz_random_rotation(self):\n",
    "        random_rotation_on_xyz_axis = np.random.rand(3) * 2 * np.pi\n",
    "        return R.from_euler('xyz', random_rotation_on_xyz_axis, degrees=False)\n",
    "    \n",
    "    def get_point_cloud_center(self, pc_points):\n",
    "        return pc_points.mean(axis=0)\n",
    "    \n",
    "    def apply_rotation(self, point, rot_mat, pcd_center):\n",
    "        return np.dot(point.reshape(1, 3), rot_mat.as_matrix().T)[0, :]\n",
    "    \n",
    "    def apply_rotation_pc(slef, points, rot_mat, pcd_center):\n",
    "        return np.dot(points, rot_mat.as_matrix().T)\n",
    "        \n",
    "    def bufferize_pointcloud(self, points, N):\n",
    "        pc = np.zeros((self.N, 3), dtype=np.float32)\n",
    "        pc[:min(self.N, points.shape[0]), :] = points[:min(self.N, points.shape[0]), :]\n",
    "        return pc\n",
    "    \n",
    "    def sample_anchor_point(self, pcd_points, pcd_tree):\n",
    "        ############# START ###########\n",
    "        ######### COMPLETE HERE #######\n",
    "        \n",
    "        ############# END #############\n",
    "        return anchor_pt, anchor_neighborhood_idxs\n",
    "    \n",
    "    def sample_positive_point(self, pcd_n_points, pcd_n_tree, anchor_pt):\n",
    "        _, noisy_anchor_nn_idx, _ = pcd_n_tree.search_knn_vector_3d(anchor_pt, 1)\n",
    "        \n",
    "        ############# START ###########\n",
    "        ######### COMPLETE HERE #######\n",
    "        \n",
    "        ############# END #############\n",
    "        \n",
    "        return pos_pt, noisy_positive_neighborhood_idxs\n",
    "    \n",
    "    def sample_negative_point(self, pcd_n_points, pcd_n_tree, anchor_pt):\n",
    "        ############# START ###########\n",
    "        ######### COMPLETE HERE #######\n",
    "        \n",
    "        ############# END #############\n",
    "    \n",
    "    def get_sampled_pointcloud(self, mesh_idx, N):\n",
    "        idxs = np.arange(0, self.pcds[mesh_idx].shape[0], 1)\n",
    "        np.random.shuffle(idxs)\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(self.pcds[mesh_idx][idxs[:N]])\n",
    "        return pcd\n",
    "    \n",
    "    def generate_test_set(self, mesh_idx, N=500):\n",
    "        \n",
    "        self.test_points = self.pcds[mesh_idx]\n",
    "        \n",
    "        ## sample test points randomly\n",
    "        idxs = np.arange(0, self.test_points.shape[0], 1)\n",
    "        np.random.shuffle(idxs)\n",
    "        self.test_points_sampled = self.test_points[idxs[:N]]\n",
    "        \n",
    "        # ## as a bonus study: you can sample keypoints from the point cloud\n",
    "        # ## using open3d and analyze the results. Keypoints are inherently easier.\n",
    "        # pcd = o3d.geometry.PointCloud()\n",
    "        # pcd.points = o3d.utility.Vector3dVector(self.pcds[mesh_idx])\n",
    "        # keypoints = o3d.geometry.keypoint.compute_iss_keypoints(pcd,\n",
    "        #                                                 salient_radius=0.005,\n",
    "        #                                                 non_max_radius=0.005,\n",
    "        #                                                 gamma_21=0.4,\n",
    "        #                                                 gamma_32=0.5)\n",
    "        # self.test_points_sampled = np.random.permutation(np.asarray(keypoints.points))\n",
    "        \n",
    "        self.test_tree = self.KDtrees[mesh_idx]\n",
    "    \n",
    "    def generate_noisy_test_set(self, mesh_idx):\n",
    "        self.test_points_n = self.pcds_n[mesh_idx]\n",
    "        self.test_tree_n = self.KDtrees_n[mesh_idx]\n",
    "        \n",
    "        test_points_sampled_n = []\n",
    "        for i in tqdm(range(self.test_points_sampled.shape[0])):\n",
    "            _, gt_nn_idx, _ = self.test_tree_n.search_knn_vector_3d(self.test_points_sampled[i], 1)\n",
    "            gt_nearest_point = self.test_points_n[gt_nn_idx].squeeze()\n",
    "            test_points_sampled_n.append(gt_nearest_point)\n",
    "\n",
    "        self.test_points_sampled_n = np.asarray(test_points_sampled_n)\n",
    "    \n",
    "    def compute_descriptors(self, tinypointnet, noisy=False):\n",
    "        tinypointnet.eval()\n",
    "        \n",
    "        if noisy:\n",
    "            queries = self.test_points_sampled_n\n",
    "            tree    = self.test_tree_n\n",
    "            points  = self.test_points_n\n",
    "        else:\n",
    "            queries = self.test_points_sampled\n",
    "            tree    = self.test_tree\n",
    "            points  = self.test_points\n",
    "        tot_queries = queries.shape[0]\n",
    "        \n",
    "        descriptors = np.zeros((tot_queries, 256), dtype=np.float32)\n",
    "        for i in tqdm(range(tot_queries)):\n",
    "            pt = queries[i]\n",
    "            \n",
    "            ## find neighborhood of points\n",
    "            _, idx, _ = tree.search_radius_vector_3d(pt, self.radius)\n",
    "            point_set = points[idx]\n",
    "\n",
    "            ## normalize the points\n",
    "            point_set = (point_set - pt)\n",
    "\n",
    "            pc = np.zeros((self.N, 3), dtype=np.float32)\n",
    "            pc[:min(self.N, point_set.shape[0]), :] = point_set[:min(self.N, point_set.shape[0]), :]\n",
    "\n",
    "            # transform\n",
    "            anchor  = torch.from_numpy(pc).unsqueeze(0).float().transpose(1,2).to(device)\n",
    "            descriptors[i, :] = tinypointnet(anchor)[0, :, 0].cpu().detach().numpy()\n",
    "        return descriptors\n",
    "\n",
    "    def __getitem__(self, _):\n",
    "        mesh_idx = np.random.randint(0, len(self.mesh))\n",
    "        \n",
    "        pcd_points = self.pcds[mesh_idx]        ## anchor will be drawn from this\n",
    "        pcd_n_points = self.pcds_n[mesh_idx]    ## positive and negative will be drawn from this\n",
    "        \n",
    "        # ANCHOR: select a random anchor point\n",
    "        anchor_pt, anchor_neighborhood_idxs = self.sample_anchor_point(pcd_points, self.KDtrees[mesh_idx])\n",
    "        \n",
    "        # POSITIVE: find corresponding point in the noisy point cloud\n",
    "        pos_pt, noisy_positive_neighborhood_idxs = self.sample_positive_point(pcd_n_points, self.KDtrees_n[mesh_idx], anchor_pt)\n",
    "\n",
    "        # NEGATIVE: find far point (at least at distance min_dist)\n",
    "        neg_pt, noisy_negative_neighborhood_idxs = self.sample_negative_point(pcd_n_points, self.KDtrees_n[mesh_idx], anchor_pt)\n",
    "        if neg_pt is None: ## it should never fail, but if it fails: restart experiment\n",
    "            quit(\"FAIL: restart experiment\")\n",
    "            \n",
    "\n",
    "        # get points\n",
    "        point_set_anchor   = pcd_points[anchor_neighborhood_idxs]\n",
    "        point_set_positive = pcd_n_points[noisy_positive_neighborhood_idxs]\n",
    "        point_set_negative = pcd_n_points[noisy_negative_neighborhood_idxs]\n",
    "        \n",
    "        if not self.is_test_set:\n",
    "            # generate a random rotation\n",
    "            rot_mat = self.get_xyz_random_rotation()\n",
    "\n",
    "            # apply the random rotation to point cloud and points\n",
    "            pcd_points_center = self.get_point_cloud_center(pcd_points)\n",
    "            pcd_n_points_center = self.get_point_cloud_center(pcd_n_points)\n",
    "            anchor_pt = self.apply_rotation(anchor_pt, rot_mat, pcd_points_center)\n",
    "            pos_pt    = self.apply_rotation(pos_pt, rot_mat, pcd_n_points_center)\n",
    "            neg_pt    = self.apply_rotation(neg_pt, rot_mat, pcd_n_points_center)\n",
    "            point_set_anchor   = self.apply_rotation_pc(point_set_anchor, rot_mat, pcd_points_center)\n",
    "            point_set_positive = self.apply_rotation_pc(point_set_positive, rot_mat, pcd_n_points_center)\n",
    "            point_set_negative = self.apply_rotation_pc(point_set_negative, rot_mat, pcd_n_points_center)\n",
    "        else:\n",
    "            rot_mat = self.common_rot_mat\n",
    "        \n",
    "        # center points around their centroid\n",
    "        point_set_anchor   = (point_set_anchor - anchor_pt)\n",
    "        point_set_positive = (point_set_positive - pos_pt)\n",
    "        point_set_negative = (point_set_negative - neg_pt)\n",
    "        \n",
    "        # copy points coordinates to a fixed dimension np.array\n",
    "        point_set_anchor   = self.bufferize_pointcloud(point_set_anchor  , self.N)\n",
    "        point_set_positive = self.bufferize_pointcloud(point_set_positive, self.N)\n",
    "        point_set_negative = self.bufferize_pointcloud(point_set_negative, self.N)\n",
    "        \n",
    "        # transform from numpy to torch.Tensor\n",
    "        point_set_anchor    = torch.from_numpy(point_set_anchor)\n",
    "        point_set_positive  = torch.from_numpy(point_set_positive)\n",
    "        point_set_negative  = torch.from_numpy(point_set_negative)\n",
    "        \n",
    "        return mesh_idx, point_set_anchor, point_set_positive, point_set_negative, anchor_pt, pos_pt, neg_pt, rot_mat.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABoR7ciUCrq_",
    "tags": []
   },
   "source": [
    "\n",
    "# Dataset Creation\n",
    "\n",
    "Now we can instantiate our training and test dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mq_sC59txbQF",
    "outputId": "e3b8102e-6c95-48d2-fcf3-e3de557051e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds  = PointCloudData(dataset_path_train, samples_per_epoch=500)\n",
    "valid_ds  = PointCloudData(dataset_path_valid, samples_per_epoch=500)\n",
    "test_ds   = PointCloudData(dataset_path_test,  samples_per_epoch=500, is_test_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC5c_b1quNFT"
   },
   "source": [
    "Creating a `Dataset` class may seem unnecessary for the most basic problems. But it really helps when the dataset and the training procedure start to get more complex.\n",
    "\n",
    "One of the most useful benefit of defining a `Dataset` class is the possiblity to use the PyTorch `Dataloader` module.\n",
    "\n",
    "By operating on the dataset directly, we are losing out on a lot of features by using a simple for loop to iterate over the data. In particular, we are missing out on:\n",
    "\n",
    "* Batching the data\n",
    "* Shuffling the data\n",
    "* Load the data in parallel using multiprocessing workers.\n",
    "\n",
    "`torch.utils.data.DataLoader` is an iterator which provides all these features. Parameters used below should be clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX2pNbMhxm0N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# warning: batch_size needs to be at least 2\n",
    "train_loader  = DataLoader( dataset=train_ds,  batch_size=50, shuffle=True  )\n",
    "valid_loader  = DataLoader( dataset=valid_ds,  batch_size=50, shuffle=False )\n",
    "test_loader   = DataLoader( dataset=test_ds,   batch_size=20, shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IzNMJKK10u4",
    "tags": []
   },
   "source": [
    "# Visualize some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "yPswsKFl10u4",
    "outputId": "8a3ba352-cd72-459c-8274-cade35cfc33d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = train_ds\n",
    "\n",
    "for (mesh_idx, _, _, _, anchor, positive, negative, rot_mat) in ds:\n",
    "    idx = mesh_idx\n",
    "    visualize(ds.pcds[idx],\n",
    "              anchor = anchor, \n",
    "              positive = positive,\n",
    "              negative = negative,\n",
    "              radius=ds.radius,\n",
    "              rot_mat=rot_mat)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPtnhEyuy9ks",
    "tags": []
   },
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HjszmGzub9M"
   },
   "source": [
    "## Network Base Module\n",
    "\n",
    "A network is defined by extending the *torch.nn.module* class. The basic structure is:\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_parameters):\n",
    "        super().__init__() # This executes the parent __init__ method\n",
    "        [...]\n",
    "\n",
    "    def forward(self, x, optional_parameters):\n",
    "        [...]\n",
    "        return out # return the output of the network\n",
    "```\n",
    "\n",
    "You need to define two methods:\n",
    "*   **\\_\\_init\\_\\_**: The constructor method. This is exectuted when the object is initialized (no need to call it explicitly). Here you have to instantiate all the network's parameters. PyTorch provides utility functions to easily initialize most of the commonly used deep learning layers.\n",
    "*   **forward**: Here you define the forward pass of the network, from the input *x* to the output (the method must return the network output). You just need to define the forward part, the back-propagation is automatically tracked by the framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpMGFh5_bj5I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multi Layer Perceptron\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size   = input_size\n",
    "        self.output_size  = output_size\n",
    "        self.conv  = nn.Conv1d(self.input_size, self.output_size, 1)\n",
    "        self.bn    = nn.BatchNorm1d(self.output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.relu(self.bn(self.conv(input)))\n",
    "\n",
    "# Fully Connected with Batch Normalization\n",
    "class FC_BN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size   = input_size\n",
    "        self.output_size  = output_size\n",
    "        self.lin  = nn.Linear(self.input_size, self.output_size)\n",
    "        self.bn    = nn.BatchNorm1d(self.output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.relu(self.bn(self.lin(input)))\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "\n",
    "        self.mlp1 = MLP(self.k, 64)\n",
    "        self.mlp2 = MLP(64, 128)\n",
    "        self.mlp3 = MLP(128, 1024)\n",
    "\n",
    "        self.fc_bn1 = FC_BN(1024, 512)\n",
    "        self.fc_bn2 = FC_BN(512,256)\n",
    "\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "    \n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (batch_size,n,3)\n",
    "\n",
    "        bs = input.size(0)\n",
    "        xb = self.mlp1(input)\n",
    "        xb = self.mlp2(xb)\n",
    "        xb = self.mlp3(xb)\n",
    "\n",
    "        pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "\n",
    "        xb = self.fc_bn1(flat)\n",
    "        xb = self.fc_bn2(xb)\n",
    "\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEQ4Zx5WoLDx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyPointNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform   = TNet(k=3) ## if you use the shot rotation matrix, this is not going to be used\n",
    "        self.feature_transform = TNet(k=64)\n",
    "\n",
    "        ############# START ###########\n",
    "        ######### COMPLETE HERE #######\n",
    "\n",
    "        ############# END #############\n",
    "\n",
    "    def forward(self, input):\n",
    "        n_pts = input.size()[2]\n",
    "        # matrix3x3 = self.input_transform(input)\n",
    "        matrix3x3 = self.shot_canonical_rotation(input, 3)\n",
    "        input_transform_output = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "\n",
    "        ############# START ###########\n",
    "        ######### COMPLETE HERE #######\n",
    "\n",
    "        ############# END #############\n",
    "\n",
    "        return global_feature\n",
    "\n",
    "    def shot_canonical_rotation(self, input, k):\n",
    "        # input.shape == (batch_size, n, k)\n",
    "        batch_size, n, _ = input.size()\n",
    "        rotation_matrices = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            features_batch = input[i]\n",
    "            centroid = torch.mean(features_batch, dim=1, keepdim=True)\n",
    "            centered_features = features_batch - centroid\n",
    "\n",
    "            if torch.any(torch.isnan(centered_features)) or torch.any(torch.isinf(centered_features)):\n",
    "                centered_features[torch.isnan(centered_features) | torch.isinf(centered_features)] = 1e-6\n",
    "\n",
    "            distances = torch.norm(centered_features, dim=0)\n",
    "\n",
    "            weights = 1.0 - distances\n",
    "            weights[weights < 0] = 0\n",
    "\n",
    "            weights_sum = torch.sum(weights)\n",
    "            if weights_sum > 0:\n",
    "                weights = weights / weights_sum\n",
    "            else:\n",
    "                weights = torch.ones_like(weights) / n\n",
    "\n",
    "            weighted_cov_matrix = torch.zeros((centered_features.size(0), centered_features.size(0)), device=input.device)\n",
    "            \n",
    "            ############# START ###########\n",
    "            ######### COMPLETE HERE #######\n",
    "            ### compute the covariance matrix\n",
    "            \n",
    "            ############# END #############\n",
    "            \n",
    "            weighted_cov_matrix += torch.eye(weighted_cov_matrix.size(-1), device=input.device) * 1e-6\n",
    "            \n",
    "            ############# START ###########\n",
    "            ######### COMPLETE HERE #######\n",
    "            ### compute the eigenvectors of covariance matrix\n",
    "            \n",
    "            ############# END #############\n",
    "            \n",
    "            rotation_matrix = V[:, :k]\n",
    "\n",
    "            for j in range(k):\n",
    "                signs = torch.sign(torch.sum(centered_features * rotation_matrix[:, j].unsqueeze(1), dim=0))\n",
    "                if torch.sum(signs >= 0) < torch.sum(signs < 0):\n",
    "                    rotation_matrix[:, j] = -rotation_matrix[:, j]\n",
    "\n",
    "            rotation_matrices.append(rotation_matrix)\n",
    "\n",
    "        return torch.stack(rotation_matrices, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P38WBTtMyFeC",
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIlTUpNPyBdK",
    "outputId": "35c75d09-f4a4-4caa-8d85-09a53d2e2912",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWSroT5TyDnt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tinypointnet = TinyPointNet()\n",
    "tinypointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqwUjESLyKv3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(tinypointnet.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAf8UGcPazjx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader=None,  epochs=45, save=True):\n",
    "    best_valid_loss = 1e10\n",
    "    ############## START #############\n",
    "    ####### COMPLETE THIS PART: put the correct loss function #######\n",
    "    # tinypointnetloss = \n",
    "    tinypointnetloss = \n",
    "    ############## END ###############\n",
    "    \n",
    "    # these lists keep track of the losses across epochs\n",
    "    train_losses, valid_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # local list of losses\n",
    "        train_loss, valid_loss = [], []\n",
    "        \n",
    "        # train \n",
    "        tinypointnet.train()\n",
    "        \n",
    "        for (_, anchor, positive, negative, _, _, _, _) in tqdm(train_loader):\n",
    "            \n",
    "            # retrieve anchors, positives and negatives batch\n",
    "            anchor   =   anchor.to(device).float().transpose(1,2)\n",
    "            positive = positive.to(device).float().transpose(1,2)\n",
    "            negative = negative.to(device).float().transpose(1,2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # let PointNetTiny model compute the descriptors\n",
    "            anchor_desc   = tinypointnet(anchor)\n",
    "            positive_desc = tinypointnet(positive)\n",
    "            negative_desc = tinypointnet(negative)\n",
    "            \n",
    "            # compute the loss associated to these descriptors\n",
    "            loss = tinypointnetloss(anchor_desc, positive_desc, negative_desc)\n",
    "            \n",
    "            # Backpropagate the gradient\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Keep track of the statistics            \n",
    "            train_loss.append(loss.item())\n",
    "            #pbar.set_postfix(loss=curr_loss)\n",
    "        \n",
    "        train_loss = np.asarray(train_loss).mean()\n",
    "        print(f'epoch {epoch} - train loss:', train_loss)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        tinypointnet.eval()\n",
    "        pbar = tqdm(valid_loader, leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (_, anchor, positive, negative, _, _, _, _) in pbar:\n",
    "                pbar.set_description(f\"valid - epoch {epoch}\")\n",
    "                \n",
    "                anchor   =   anchor.to(device).float().transpose(1,2)\n",
    "                positive = positive.to(device).float().transpose(1,2)\n",
    "                negative = negative.to(device).float().transpose(1,2)\n",
    "                \n",
    "                anchor_desc   = tinypointnet(anchor)\n",
    "                positive_desc = tinypointnet(positive)\n",
    "                negative_desc = tinypointnet(negative)\n",
    "                loss = tinypointnetloss(anchor_desc, positive_desc, negative_desc)\n",
    "                curr_loss = loss.item()\n",
    "                \n",
    "                valid_loss.append(curr_loss)\n",
    "                \n",
    "                pbar.set_postfix(loss=curr_loss)\n",
    "        \n",
    "        valid_loss = np.asarray(valid_loss).mean()\n",
    "        print(f'epoch {epoch} - valid loss:', valid_loss)\n",
    "        valid_losses.append(valid_loss)        \n",
    "\n",
    "        # save the model\n",
    "        if save and valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            if running_on_colab:\n",
    "                path = os.path.join(drive_path, \"MyDrive\", \"tinypointnetmodel.yml\")\n",
    "            else:\n",
    "                path = os.path.join(\"tinypointnetmodel.yml\")\n",
    "            print(\"best_valid_loss:\", best_valid_loss, \"saving model at\", path)\n",
    "            torch.save(tinypointnet.state_dict(), path)\n",
    "    return train_losses, valid_losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCioSo6kyU5M",
    "outputId": "e6026fe7-f48c-47a1-9812-40269bd13b62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, valid_losses = train(tinypointnet, train_loader, valid_loader, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxxvdXzn10u5"
   },
   "source": [
    "## Visualize the Training trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22ECIGIZ10u6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numpy_ewma_vectorized_v2(data, window=10):\n",
    "    # Return the Exponentially Weighted Moving Average\n",
    "    # for better visualizing the \"trend\" of the metrics\n",
    "\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "    n = data.shape[0]\n",
    "\n",
    "    pows = alpha_rev**(np.arange(n+1))\n",
    "\n",
    "    scale_arr = 1/pows[:-1]\n",
    "    offset = data[0]*pows[1:]\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2PDOXU710u6"
   },
   "source": [
    "### Plot the trend of train and valid losses\n",
    "By using an Exponentially Weighted Moving Average of the losses,\n",
    "we can better understand the behaviour of our network by filtering out\n",
    "the noisy *local values* and focusing more on the *global trend*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "3PIDERVU10u6",
    "outputId": "7d9329a7-555c-4016-b9f9-97f3f0558d97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train losses\", color='r', alpha=0.2)\n",
    "plt.plot(valid_losses, label=\"valid losses\", color='b', alpha=0.2)\n",
    "plt.plot(numpy_ewma_vectorized_v2(np.array(train_losses)), label=\"train losses EMA\", color='r')\n",
    "plt.plot(numpy_ewma_vectorized_v2(np.array(valid_losses)), label=\"valid losses EMA\", color='b')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irrVJH1UJb92",
    "tags": []
   },
   "source": [
    "# Test: feature matching\n",
    "\n",
    "Let's compute the model test metrics\n",
    "\n",
    "> First we need to load the best model weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IqRQrxg10u6",
    "outputId": "20011f01-8a3d-4f69-ec9e-f93b838ce5f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if running_on_colab:\n",
    "    path = os.path.join(drive_path, \"MyDrive\", \"tinypointnetmodel.yml\")\n",
    "else:\n",
    "    path = os.path.join(\"tinypointnetmodel.yml\")\n",
    "tinypointnet = TinyPointNet()\n",
    "tinypointnet.load_state_dict(torch.load(path))\n",
    "tinypointnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PI4YkY6Od2PH",
    "outputId": "d70c36ee-7144-486e-fad2-c72ac65539ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds.generate_test_set(0, 2000)\n",
    "\n",
    "## build the ground truth nearest neighbors\n",
    "## in other words, find thepoints in the noisy test points\n",
    "## that are the nearest neighbors to the original, sampled, test points\n",
    "test_ds.generate_noisy_test_set(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the sampled test points\n",
    "Little red spheres represent the test points sampled from the original test mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(test_ds.test_points_sampled_n)\n",
    "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "geoms = [pcd]\n",
    "    \n",
    "# visualize the colored point cloud\n",
    "if running_on_colab:\n",
    "    draw_geometries(geoms)\n",
    "else:\n",
    "    o3d.visualization.draw_geometries(geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcd = test_ds.get_sampled_pointcloud(mesh_idx=0, N=5000)\n",
    "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "geoms = [pcd]\n",
    "for point in test_ds.test_points_sampled_n:\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1e-3)\n",
    "    sphere.translate(point)\n",
    "    sphere.paint_uniform_color([1, 0, 0])\n",
    "    geoms.append(sphere)\n",
    "    \n",
    "# visualize the colored point cloud\n",
    "if running_on_colab:\n",
    "    draw_geometries(geoms)\n",
    "else:\n",
    "    o3d.visualization.draw_geometries(geoms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the descriptor of each point in each point set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3jBS-ev10u6",
    "outputId": "530e796e-d594-44a2-9b5e-4d2caf9786d8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "descs   = test_ds.compute_descriptors(tinypointnet)\n",
    "descs_n = test_ds.compute_descriptors(tinypointnet, noisy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matching time!\n",
    "In other words, get the descriptor from the noisy point cloud which is closest to the query descriptor from the original point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcd = test_ds.get_sampled_pointcloud(mesh_idx=0, N=5000)\n",
    "pcd.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "geoms = [pcd]\n",
    "for row in tqdm(range(test_ds.test_points_sampled_n.shape[0])):\n",
    "    anchor       = test_ds.test_points_sampled[row]\n",
    "    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1e-3)\n",
    "    sphere.translate(anchor)\n",
    "    sphere.paint_uniform_color([1, 0, 0])\n",
    "    geoms.append(sphere)\n",
    "\n",
    "if running_on_colab:\n",
    "    draw_geometries(geoms)\n",
    "else:\n",
    "    o3d.visualization.draw_geometries(geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct = tot = 0\n",
    "\n",
    "for row in tqdm(range(test_ds.test_points_sampled.shape[0])):\n",
    "    desc = descs[row, :]\n",
    "    dists = []\n",
    "    anchor       = test_ds.test_points_sampled[row]\n",
    "    true_near_pt = test_ds.test_points_sampled_n[row]\n",
    "\n",
    "    for row2 in range(test_ds.test_points_sampled_n.shape[0]):\n",
    "        desc2 = descs_n[row2, :]\n",
    "        dist = np.linalg.norm(desc - desc2)\n",
    "        dists.append(dist)\n",
    "\n",
    "    min_row = np.argmin(np.asarray(dists))\n",
    "\n",
    "    pred_pt = test_ds.test_points_sampled_n[min_row].squeeze()\n",
    "\n",
    "    dist = np.linalg.norm(true_near_pt - pred_pt)\n",
    "    \n",
    "    # visualize(test_ds.test_points_sampled,\n",
    "    #           anchor = anchor, \n",
    "    #           positive = pred_pt,\n",
    "    #           radius=test_ds.radius)\n",
    "    \n",
    "    if dist<test_ds.radius:\n",
    "        correct += 1\n",
    "    tot += 1\n",
    "\n",
    "print()\n",
    "print(f\"accuracy: {correct*100/tot:6.3f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "VWcO-JoNzH17",
    "7IzNMJKK10u4",
    "BPtnhEyuy9ks"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv111",
   "language": "python",
   "name": "venv111"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
